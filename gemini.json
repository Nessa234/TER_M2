{
    "paragraphes": [
      {
        "paragraph_id": 1,
        "model_name": "Aether-Net",
        "parameters": "14.2 billion",
        "hardware": "128 NVIDIA H100 GPUs",
        "training_time": "22 days",
        "country": "Germany",
        "year": "2024"
      },
      {
        "paragraph_id": 2,
        "model_name": "Vortex-Alpha",
        "parameters": "190 billion",
        "hardware": "1,024 NVIDIA H200 GPUs",
        "training_time": "74 days",
        "country": "UNKNOWN",
        "year": "2025"
      },
      {
        "paragraph_id": 3,
        "model_name": "Oasis-Refine",
        "parameters": "UNKNOWN",
        "hardware": "256 NVIDIA A100 GPUs",
        "training_time": "31 days",
        "country": "Japan",
        "year": "UNKNOWN"
      },
      {
        "paragraph_id": 4,
        "model_name": "Lumina-9B",
        "parameters": "9.4 billion",
        "hardware": "UNKNOWN",
        "training_time": "12 days",
        "country": "Canada",
        "year": "2024"
      },
      {
        "paragraph_id": 5,
        "model_name": "Solas-Prime",
        "parameters": "65 billion",
        "hardware": "256 NVIDIA H100 GPUs",
        "training_time": "48 days",
        "country": "Ireland",
        "year": "2025"
      },
      {
        "paragraph_id": 6,
        "model_name": "Zephyr-Lite",
        "parameters": "3.1 billion",
        "hardware": "16 NVIDIA A100 GPUs",
        "training_time": "5 days",
        "country": "UNKNOWN",
        "year": "2024"
      },
      {
        "paragraph_id": 7,
        "model_name": "Titan-Core",
        "parameters": "520 billion",
        "hardware": "4,096 Google TPU v5p units",
        "training_time": "115 days",
        "country": "United States",
        "year": "UNKNOWN"
      },
      {
        "paragraph_id": 8,
        "model_name": "Calyx-Vision",
        "parameters": "22 billion",
        "hardware": "64 NVIDIA H100 GPUs",
        "training_time": "20 days",
        "country": "France",
        "year": "2024"
      },
      {
        "paragraph_id": 9,
        "model_name": "Nebula-9",
        "parameters": "90 billion",
        "hardware": "UNKNOWN",
        "training_time": "55 days",
        "country": "Switzerland",
        "year": "2025"
      },
      {
        "paragraph_id": 10,
        "model_name": "Icarus-70B",
        "parameters": "70 billion",
        "hardware": "128 NVIDIA A100 GPUs",
        "training_time": "28 days",
        "country": "Greece",
        "year": "UNKNOWN"
      },
      {
        "paragraph_id": 11,
        "model_name": "Mesa-Large",
        "parameters": "115 billion",
        "hardware": "512 NVIDIA H100 GPUs",
        "training_time": "68 days",
        "country": "Australia",
        "year": "2025"
      },
      {
        "paragraph_id": 12,
        "model_name": "Kinetico-V",
        "parameters": "45 billion",
        "hardware": "256 NVIDIA H200 GPUs",
        "training_time": "40 days",
        "country": "Singapore",
        "year": "2024"
      },
      {
        "paragraph_id": 13,
        "model_name": "Selva-Small",
        "parameters": "2.1 billion",
        "hardware": "16 NVIDIA A100 GPUs",
        "training_time": "4 days",
        "country": "Brazil",
        "year": "2024"
      },
      {
        "paragraph_id": 14,
        "model_name": "Polaris-X",
        "parameters": "310 billion",
        "hardware": "UNKNOWN",
        "training_time": "98 days",
        "country": "Finland",
        "year": "2025"
      },
      {
        "paragraph_id": 15,
        "model_name": "Aura-5B",
        "parameters": "5.4 billion",
        "hardware": "32 NVIDIA H100 GPUs",
        "training_time": "9 days",
        "country": "Italy",
        "year": "UNKNOWN"
      },
      {
        "paragraph_id": 16,
        "model_name": "Zenith-Prime",
        "parameters": "185 billion",
        "hardware": "2,048 Huawei Ascend 910B NPUs",
        "training_time": "92 days",
        "country": "China",
        "year": "2025"
      },
      {
        "paragraph_id": 17,
        "model_name": "Echo-Mini",
        "parameters": "1.2 billion",
        "hardware": "8 NVIDIA A100 GPUs",
        "training_time": "3 days",
        "country": "Denmark",
        "year": "2024"
      },
      {
        "paragraph_id": 18,
        "model_name": "Atlas-Pro",
        "parameters": "68 billion",
        "hardware": "256 NVIDIA H100 GPUs",
        "training_time": "45 days",
        "country": "UNKNOWN",
        "year": "2025"
      },
      {
        "paragraph_id": 19,
        "model_name": "Mirage-50B",
        "parameters": "50 billion",
        "hardware": "128 NVIDIA H100 GPUs",
        "training_time": "32 days",
        "country": "United Arab Emirates",
        "year": "2024"
      },
      {
        "paragraph_id": 20,
        "model_name": "Boreal-25B",
        "parameters": "25 billion",
        "hardware": "64 NVIDIA A100 GPUs",
        "training_time": "24 days",
        "country": "Canada",
        "year": "2025"
      }
    ]
  }